== Design decisions ==

==== Patch target file if source is not found ====

If while patching the source file is not found, *patch.py* tries to patch
target filename. This logic is used to process old style manual patches
that were made by coparing backup file (with some fancy .old extension)
with modified version that holds original name.

==== "Already patched" detection ====

_unified diff format_ doesn't allow to correctly validate if file is
already patched, but only to check if it could be patched. It is because
in some rare cases it is possible to apply the same patch several times
(see 04check_patched example in tests).

Checksum checks are almost 100% reliable, but in this case it will be
impossible to patch files that are different in lines not covered by
unified diff context. Actually, this "weakness" of unified format is
actually a feature that allows to apply non-conlicting patches in different
order. Version control systems do this during merges.


== Parser no.0 - Brute Force ==

Versions 8.06 up to 10.04.

The logic is most straightforward. Read one line, detect to which part of
Diff it belongs (free header, filename header, hunk) and parse it in the
part responsible for this stuff.

The parser code is one big `for` loop with a lot of `if`s that check
current state (stored in local boolean variables `header` and `filenames`).
If neither `header` nor `filenames` is set then we are in the state of
parsing hunk.

Every parsing part processes line and switches state by modifying shared
variables, so that the next fetched line could be processed by different
part is required. So, every parsing part knows when it finished processing
and to which state it should switch.

For Unified format is very simple and such parser fits it nicely. However,
for other formats it may not be clear where a line should belong and `if`s
should not only check state variables, but also the line itself (in this
case line is called "context"). These `if`s should also be placed in
specific order or they can lose the line.

For example, `header` parsing block consumes lines until it encounters line
that starts with `--- `. This line belongs to `filenames` block, which
should process it. `headers` switches state to `filenames`, but if
`filename` state check was already done for this line - this line will be
lost.

The biggest problem in this parser is that every line (context) and state
are checked in one big for/if/if/if/.. cycle. While it is easy to write
such parser, it is very hard to extend it. Blocks are not explicitly
chained, and all `if` checks are run again and again for every line. It is
very hard to trace current state and estimate how new modifications will
affect parsing process.

With growing number of state variables it is easy to overlook some
combination. Context checks may also interfere. Designing recovery from
invalid input would be a nightmare.


== Parser no.1 - Block Context ==

Versions ___

So the first thing to make parser code more clean and maintainable is to
allow parser blocks fetch lines from input stream directly without waiting
the main cycle to complete. Block reads as many lines as it wants, and
switches state when finished. All lines that belong to this block could be
called "block context" and are not exposed to main `if` cycle. So there are
less chances that line that should be processed in this part of the parser
is intercepted by some other rule.

Let's call this feature of Parser no.1 "isolation of block context".

However, block context can not be fully separated. Sometimes decision about
switching state depends on the read line itself, and this line may already
belong other "block context". Current block should switch state to give
this line to its owner. For example, when header parser reads line that
starts with "--- " - it should switch state and pass this line to filename
parser. The filename parser is the owner block that should be called before
the end of the cycle to avoid line being overwritten. In case of `if`s
structure that means owner's block check should be located under part of
the code that switched state.

So each block still knows about the next state or states. It should make a
decision where to switch next. Hence it should know about "block contexts"
of its successors. This bloats and complicates code.

To simplify the code, it is possible to prevent blocks from analysing
each other's context for making switch. The block should only check that
line doesn't belong to its context and switch state to pass control
further.

"block context separation" is another feature of Parser no.2.

It not a complete separation in the sence that header parser still knows
that line starting with "--- " doesn't belong to it. It switches state by
setting `headscan` to False and `filescan` to True and that's all. No
parsing block makes assumptions or decisions where to pass the processing.
There is only one way to switch from parsing block. If there should be a
decision what is to be parsed next, then this decision should be made by
a piece of code that doesn't parse, but just analyzes context to make a
switch. The problem with arranging pieces in correct order still persists.

To solve rearrangement problem it is necessary to either reinvent GOTO or
to be able to reinsert analyzed string back into stream for fetching in
the next cycle after state has already been switched.

It is possible to illustrate chicken and egg problem when two blocks
analyze each others context to pass control from one to other and could
not be rearranged, because at the end of processing the current block
should always be higher than the other, because it needs to pass the line.

The solution can be in:
- skip fetching line on the next cycle
- reinsert line into the stream
- wrapper switch that judges who gets the next line, this requires one more
  state variable, and that blocks process lines one by one
  
Reinserting lines can provide some performance overhead, wrapper switch
complites parser, so skip line fetching may be a good solution.

